{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "from scipy.stats import loguniform, uniform, randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_distribution = {'penalty': ['l1', 'l2'], 'C': loguniform(0.001, 100), 'solver': ['newton-cg','sag','saga','lbfgs']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3perc_lag3 = pd.read_excel(\"data/model_inputs2/x_train_3perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "X_test_3perc_lag3 = pd.read_excel(\"data/model_inputs2/x_test_3perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_train_3perc_lag3 = pd.read_excel(\"data/model_inputs2/y_train_3perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_test_3perc_lag3 = pd.read_excel(\"data/model_inputs2/y_test_3perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "\n",
    "X_train_3perc_lag7 = pd.read_excel(\"data/model_inputs2/x_train_3perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "X_test_3perc_lag7 = pd.read_excel(\"data/model_inputs2/x_test_3perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_train_3perc_lag7 = pd.read_excel(\"data/model_inputs2/y_train_3perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_test_3perc_lag7 = pd.read_excel(\"data/model_inputs2/y_test_3perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "\n",
    "X_train_5perc_lag3 = pd.read_excel(\"data/model_inputs2/x_train_5perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "X_test_5perc_lag3 = pd.read_excel(\"data/model_inputs2/x_test_5perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_train_5perc_lag3 = pd.read_excel(\"data/model_inputs2/y_train_5perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_test_5perc_lag3 = pd.read_excel(\"data/model_inputs2/y_test_5perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "\n",
    "X_train_5perc_lag7 = pd.read_excel(\"data/model_inputs2/x_train_5perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "X_test_5perc_lag7 = pd.read_excel(\"data/model_inputs2/x_test_5perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_train_5perc_lag7 = pd.read_excel(\"data/model_inputs2/y_train_5perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_test_5perc_lag7 = pd.read_excel(\"data/model_inputs2/y_test_5perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote(X_train, y_train):\n",
    "    sm = SMOTE(sampling_strategy='not majority')\n",
    "    X_train_oversampled, y_train_oversampled = sm.fit_resample(X_train, y_train)\n",
    "    return X_train_oversampled, y_train_oversampled\n",
    "\n",
    "def random_oversampler(X_train, y_train):\n",
    "    oversample = RandomOverSampler(sampling_strategy='not majority')\n",
    "    X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
    "    return X_over, y_over\n",
    "\n",
    "def adasyn(X_train, y_train):\n",
    "    ada = ADASYN(sampling_strategy = 'not majority')\n",
    "    X_resampled, y_resampled = ADASYN().fit_resample(X_train, y_train)\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 combinations without tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>perc_threshold</th>\n",
       "      <th>lag</th>\n",
       "      <th>oversampling</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>pred_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>3perc</td>\n",
       "      <td>3</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.465545</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.451517</td>\n",
       "      <td>{-1: 64, 0: 74, 1: 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>3perc</td>\n",
       "      <td>3</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>0.493101</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>0.479296</td>\n",
       "      <td>{-1: 64, 0: 76, 1: 28}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>3perc</td>\n",
       "      <td>3</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.511533</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.451369</td>\n",
       "      <td>{-1: 83, 0: 48, 1: 37}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>3perc</td>\n",
       "      <td>7</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.401391</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.333796</td>\n",
       "      <td>{-1: 29, 0: 47, 1: 92}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>3perc</td>\n",
       "      <td>7</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>0.363095</td>\n",
       "      <td>0.403882</td>\n",
       "      <td>0.363095</td>\n",
       "      <td>0.357793</td>\n",
       "      <td>{-1: 32, 0: 54, 1: 82}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>3perc</td>\n",
       "      <td>7</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.394820</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.350362</td>\n",
       "      <td>{-1: 44, 0: 49, 1: 75}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>3</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.746075</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.733575</td>\n",
       "      <td>{-1: 9, 0: 143, 1: 16}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>3</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.749008</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.765297</td>\n",
       "      <td>{-1: 9, 0: 156, 1: 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>3</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.729507</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.709673</td>\n",
       "      <td>{-1: 8, 0: 140, 1: 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.663051</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.637205</td>\n",
       "      <td>{-1: 1, 0: 126, 1: 41}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.653412</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.659144</td>\n",
       "      <td>{-1: 2, 0: 139, 1: 27}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>0.601190</td>\n",
       "      <td>0.648626</td>\n",
       "      <td>0.601190</td>\n",
       "      <td>0.620768</td>\n",
       "      <td>{0: 125, 1: 43}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model perc_threshold  lag        oversampling  accuracy  \\\n",
       "0   Logistic Regression          3perc    3               smote  0.452381   \n",
       "1   Logistic Regression          3perc    3  random_oversampler  0.482143   \n",
       "2   Logistic Regression          3perc    3              adasyn  0.458333   \n",
       "3   Logistic Regression          3perc    7               smote  0.339286   \n",
       "4   Logistic Regression          3perc    7  random_oversampler  0.363095   \n",
       "5   Logistic Regression          3perc    7              adasyn  0.357143   \n",
       "6   Logistic Regression          5perc    3               smote  0.738095   \n",
       "7   Logistic Regression          5perc    3  random_oversampler  0.803571   \n",
       "8   Logistic Regression          5perc    3              adasyn  0.708333   \n",
       "9   Logistic Regression          5perc    7               smote  0.619048   \n",
       "10  Logistic Regression          5perc    7  random_oversampler  0.666667   \n",
       "11  Logistic Regression          5perc    7              adasyn  0.601190   \n",
       "\n",
       "    precision    recall        f1              pred_count  \n",
       "0    0.465545  0.452381  0.451517  {-1: 64, 0: 74, 1: 30}  \n",
       "1    0.493101  0.482143  0.479296  {-1: 64, 0: 76, 1: 28}  \n",
       "2    0.511533  0.458333  0.451369  {-1: 83, 0: 48, 1: 37}  \n",
       "3    0.401391  0.339286  0.333796  {-1: 29, 0: 47, 1: 92}  \n",
       "4    0.403882  0.363095  0.357793  {-1: 32, 0: 54, 1: 82}  \n",
       "5    0.394820  0.357143  0.350362  {-1: 44, 0: 49, 1: 75}  \n",
       "6    0.746075  0.738095  0.733575  {-1: 9, 0: 143, 1: 16}  \n",
       "7    0.749008  0.803571  0.765297   {-1: 9, 0: 156, 1: 3}  \n",
       "8    0.729507  0.708333  0.709673  {-1: 8, 0: 140, 1: 20}  \n",
       "9    0.663051  0.619048  0.637205  {-1: 1, 0: 126, 1: 41}  \n",
       "10   0.653412  0.666667  0.659144  {-1: 2, 0: 139, 1: 27}  \n",
       "11   0.648626  0.601190  0.620768         {0: 125, 1: 43}  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_col, lag_col, oversampling_method, accuracy, precision, recall, f1, pred_count = [], [], [], [], [], [], [], []\n",
    "\n",
    "for perc in ['3perc', '5perc']:\n",
    "    for lag in [3, 7]:\n",
    "        for oversampling in ['smote', 'random_oversampler', 'adasyn']:\n",
    "            X_train = eval(f'X_train_{perc}_lag{lag}')\n",
    "            X_test = eval(f'X_test_{perc}_lag{lag}')\n",
    "            y_train = eval(f'y_train_{perc}_lag{lag}')\n",
    "            y_test = eval(f'y_test_{perc}_lag{lag}')\n",
    "\n",
    "            # oversampling\n",
    "            if oversampling == 'smote':\n",
    "                X_train_oversampled, y_train_oversampled = smote(X_train, y_train)\n",
    "            elif oversampling == 'random_oversampler':\n",
    "                X_train_oversampled, y_train_oversampled = random_oversampler(X_train, y_train)\n",
    "            else:\n",
    "                X_train_oversampled, y_train_oversampled = adasyn(X_train, y_train)\n",
    "\n",
    "            # fit and predict\n",
    "            logreg = LogisticRegression()\n",
    "            pred = logreg.fit(X_train_oversampled, y_train_oversampled).predict(X_test)\n",
    "\n",
    "            # update columns\n",
    "            perc_col.append(perc)\n",
    "            lag_col.append(lag)\n",
    "            oversampling_method.append(oversampling)\n",
    "            accuracy.append(accuracy_score(y_test, pred))\n",
    "            precision.append(precision_score(y_test, pred, average='weighted'))\n",
    "            recall.append(recall_score(y_test, pred, average='weighted'))\n",
    "            f1.append(f1_score(y_test, pred, average='weighted'))\n",
    "            pred_count.append(dict(pd.Series(pred).value_counts().sort_index()))\n",
    "\n",
    "results_no_tuning = pd.DataFrame({\n",
    "    'model': \"Logistic Regression\",\n",
    "    'perc_threshold': perc_col,\n",
    "    'lag': lag_col,\n",
    "    'oversampling': oversampling_method,\n",
    "    'accuracy': accuracy,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1': f1,\n",
    "    'pred_count': pred_count\n",
    "})\n",
    "results_no_tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning for best combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_col, lag_col, oversampling_method, param, accuracy, precision, recall, f1 = [], [], [], [], [], [], [], []\n",
    "\n",
    "perc = '5perc'\n",
    "lag = 3\n",
    "oversampling = 'random_oversampler'\n",
    "X_train = eval(f'X_train_{perc}_lag{lag}')\n",
    "X_test = eval(f'X_test_{perc}_lag{lag}')\n",
    "y_train = eval(f'y_train_{perc}_lag{lag}')\n",
    "y_test = eval(f'y_test_{perc}_lag{lag}')\n",
    "\n",
    "# oversampling\n",
    "if oversampling == 'smote':\n",
    "    X_train_oversampled, y_train_oversampled = smote(X_train, y_train)\n",
    "elif oversampling == 'random_oversampler':\n",
    "    X_train_oversampled, y_train_oversampled = random_oversampler(X_train, y_train)\n",
    "else:\n",
    "    X_train_oversampled, y_train_oversampled = adasyn(X_train, y_train)\n",
    "\n",
    "# tuning\n",
    "logreg = LogisticRegression()\n",
    "logreg_clf = RandomizedSearchCV(logreg, logreg_distribution, n_iter=100, scoring=['accuracy', 'recall_weighted', 'precision_weighted', 'f1_weighted'], refit='f1_weighted', random_state=42)\n",
    "logreg_search = logreg_clf.fit(X_train_oversampled, y_train_oversampled)\n",
    "\n",
    "# update columns\n",
    "perc_col.append([perc]*100)\n",
    "lag_col.append([lag]*100)\n",
    "oversampling_method.append([oversampling]*100)\n",
    "param.append(logreg_search.cv_results_['params'])\n",
    "accuracy.append(logreg_search.cv_results_['mean_test_accuracy'])\n",
    "precision.append(logreg_search.cv_results_['mean_test_precision_weighted'])\n",
    "recall.append(logreg_search.cv_results_['mean_test_recall_weighted'])\n",
    "f1.append(logreg_search.cv_results_['mean_test_f1_weighted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'model': \"Logistic Regression\",\n",
    "    'perc_threshold': np.array(perc_col).flatten(),\n",
    "    'lag': np.array(lag_col).flatten(),\n",
    "    'oversampling': np.array(oversampling_method).flatten(),\n",
    "    'parameters': np.array(param).flatten(),\n",
    "    'accuracy': np.array(accuracy).flatten(),\n",
    "    'precision': np.array(precision).flatten(),\n",
    "    'recall': np.array(recall).flatten(),\n",
    "    'f1': np.array(f1).flatten(),\n",
    "}).sort_values(by=\"f1\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>perc_threshold</th>\n",
       "      <th>lag</th>\n",
       "      <th>oversampling</th>\n",
       "      <th>parameters</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>3</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>{'C': 0.006026889128682509, 'penalty': 'l1', '...</td>\n",
       "      <td>0.700302</td>\n",
       "      <td>0.719577</td>\n",
       "      <td>0.700302</td>\n",
       "      <td>0.698334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>3</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>{'C': 0.001339971723117972, 'penalty': 'l1', '...</td>\n",
       "      <td>0.695888</td>\n",
       "      <td>0.718191</td>\n",
       "      <td>0.695888</td>\n",
       "      <td>0.694819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>3</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>{'C': 0.0010656401760606444, 'penalty': 'l1', ...</td>\n",
       "      <td>0.691479</td>\n",
       "      <td>0.712268</td>\n",
       "      <td>0.691479</td>\n",
       "      <td>0.690184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>3</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>{'C': 0.0012674255898937226, 'penalty': 'l2', ...</td>\n",
       "      <td>0.662685</td>\n",
       "      <td>0.664080</td>\n",
       "      <td>0.662685</td>\n",
       "      <td>0.653345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>3</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>{'C': 0.0010833297073737746, 'penalty': 'l2', ...</td>\n",
       "      <td>0.659900</td>\n",
       "      <td>0.663952</td>\n",
       "      <td>0.659900</td>\n",
       "      <td>0.651294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>3</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>{'C': 0.0015991003111214825, 'penalty': 'l2', ...</td>\n",
       "      <td>0.661296</td>\n",
       "      <td>0.660391</td>\n",
       "      <td>0.661296</td>\n",
       "      <td>0.650203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>3</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>{'C': 0.0014857392806279237, 'penalty': 'l2', ...</td>\n",
       "      <td>0.659436</td>\n",
       "      <td>0.659643</td>\n",
       "      <td>0.659436</td>\n",
       "      <td>0.649256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>3</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>{'C': 0.0016832027985721903, 'penalty': 'l2', ...</td>\n",
       "      <td>0.660135</td>\n",
       "      <td>0.658807</td>\n",
       "      <td>0.660135</td>\n",
       "      <td>0.648767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>3</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>{'C': 0.0019517224641449492, 'penalty': 'l2', ...</td>\n",
       "      <td>0.660136</td>\n",
       "      <td>0.657225</td>\n",
       "      <td>0.660136</td>\n",
       "      <td>0.647734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>3</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>{'C': 0.0021147447960615704, 'penalty': 'l2', ...</td>\n",
       "      <td>0.658976</td>\n",
       "      <td>0.655355</td>\n",
       "      <td>0.658976</td>\n",
       "      <td>0.646270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model perc_threshold  lag        oversampling  \\\n",
       "0  Logistic Regression          5perc    3  random_oversampler   \n",
       "1  Logistic Regression          5perc    3  random_oversampler   \n",
       "2  Logistic Regression          5perc    3  random_oversampler   \n",
       "3  Logistic Regression          5perc    3  random_oversampler   \n",
       "4  Logistic Regression          5perc    3  random_oversampler   \n",
       "5  Logistic Regression          5perc    3  random_oversampler   \n",
       "6  Logistic Regression          5perc    3  random_oversampler   \n",
       "7  Logistic Regression          5perc    3  random_oversampler   \n",
       "8  Logistic Regression          5perc    3  random_oversampler   \n",
       "9  Logistic Regression          5perc    3  random_oversampler   \n",
       "\n",
       "                                          parameters  accuracy  precision  \\\n",
       "0  {'C': 0.006026889128682509, 'penalty': 'l1', '...  0.700302   0.719577   \n",
       "1  {'C': 0.001339971723117972, 'penalty': 'l1', '...  0.695888   0.718191   \n",
       "2  {'C': 0.0010656401760606444, 'penalty': 'l1', ...  0.691479   0.712268   \n",
       "3  {'C': 0.0012674255898937226, 'penalty': 'l2', ...  0.662685   0.664080   \n",
       "4  {'C': 0.0010833297073737746, 'penalty': 'l2', ...  0.659900   0.663952   \n",
       "5  {'C': 0.0015991003111214825, 'penalty': 'l2', ...  0.661296   0.660391   \n",
       "6  {'C': 0.0014857392806279237, 'penalty': 'l2', ...  0.659436   0.659643   \n",
       "7  {'C': 0.0016832027985721903, 'penalty': 'l2', ...  0.660135   0.658807   \n",
       "8  {'C': 0.0019517224641449492, 'penalty': 'l2', ...  0.660136   0.657225   \n",
       "9  {'C': 0.0021147447960615704, 'penalty': 'l2', ...  0.658976   0.655355   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.700302  0.698334  \n",
       "1  0.695888  0.694819  \n",
       "2  0.691479  0.690184  \n",
       "3  0.662685  0.653345  \n",
       "4  0.659900  0.651294  \n",
       "5  0.661296  0.650203  \n",
       "6  0.659436  0.649256  \n",
       "7  0.660135  0.648767  \n",
       "8  0.660136  0.647734  \n",
       "9  0.658976  0.646270  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.006026889128682509, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params, best_perc, best_lag, best_oversampling = results.iloc[0]['parameters'], results.iloc[0]['perc_threshold'], results.iloc[0]['lag'], results.iloc[0]['oversampling']\n",
    "best_model = LogisticRegression(**best_params)\n",
    "X_train, y_train, x_test, y_test = eval(f'X_train_{best_perc}_lag{best_lag}'), eval(f'y_train_{best_perc}_lag{best_lag}'), eval(f'X_test_{best_perc}_lag{best_lag}'), eval(f'y_test_{best_perc}_lag{best_lag}')\n",
    "\n",
    "if best_oversampling == 'smote':\n",
    "    X_train_oversampled, y_train_oversampled = smote(X_train, y_train)\n",
    "elif best_oversampling == 'random_oversampler':\n",
    "    X_train_oversampled, y_train_oversampled = random_oversampler(X_train, y_train)\n",
    "else:\n",
    "    X_train_oversampled, y_train_oversampled = adasyn(X_train, y_train)\n",
    "\n",
    "best_model.fit(X_train_oversampled, y_train_oversampled)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(actual, predictions):\n",
    "    print(f\"accuracy: {accuracy_score(actual, predictions)}\")\n",
    "    print(f\"precision: {precision_score(actual, predictions, average='weighted')}\")\n",
    "    print(f\"recall: {recall_score(actual, predictions, average='weighted')}\")\n",
    "    print(f\"f1: {f1_score(actual, predictions, average='weighted')}\")\n",
    "    print(f\"confusion matrix:\\n{confusion_matrix(actual, predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.75\n",
      "precision: 0.7459415584415584\n",
      "recall: 0.75\n",
      "f1: 0.7438158593509797\n",
      "confusion matrix:\n",
      "[[ 12   9   0]\n",
      " [ 23 114   0]\n",
      " [  1   9   0]]\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_model.predict(X_test)\n",
    "print_results(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7665276950565812\n",
      "precision: 0.9217839401019193\n",
      "recall: 0.7665276950565812\n",
      "f1: 0.8252744374095169\n",
      "confusion matrix:\n",
      "[[  48   16    2]\n",
      " [ 183 1221  169]\n",
      " [   4   18   18]]\n"
     ]
    }
   ],
   "source": [
    "X_full = pd.concat([X_train, X_test])\n",
    "y_full = pd.concat([y_train, y_test])\n",
    "\n",
    "full_pred = best_model.predict(X_full)\n",
    "print_results(y_full, full_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Business Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1679, 11)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_df_x = pd.concat([X_train, X_test])\n",
    "whole_df_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df_x['year'] = whole_df_x.index.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp_strategy_annual_return</th>\n",
       "      <th>exp_benchmark_annual_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.164536</td>\n",
       "      <td>0.112846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>0.173690</td>\n",
       "      <td>0.185753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>-0.113091</td>\n",
       "      <td>-0.070634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>0.288443</td>\n",
       "      <td>0.288443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>-0.504476</td>\n",
       "      <td>0.152929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>0.284494</td>\n",
       "      <td>0.289230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>-0.218343</td>\n",
       "      <td>-0.249185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      exp_strategy_annual_return  exp_benchmark_annual_return\n",
       "2016                    0.164536                     0.112846\n",
       "2017                    0.173690                     0.185753\n",
       "2018                   -0.113091                    -0.070634\n",
       "2019                    0.288443                     0.288443\n",
       "2020                   -0.504476                     0.152929\n",
       "2021                    0.284494                     0.289230\n",
       "2022                   -0.218343                    -0.249185"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_metric_results = pd.DataFrame(columns=['exp_strategy_annual_return', 'exp_benchmark_annual_return'])\n",
    "\n",
    "for year in [2016, 2017, 2018, 2019, 2020, 2021, 2022]:\n",
    "    year_data = whole_df_x[whole_df_x['year'] == year]\n",
    "    # year_data = year_data.set_index('index')\n",
    "    year_data = year_data.drop(['year'], axis = 1)\n",
    "    predict_x = best_model.predict(np.array(year_data)) \n",
    "    # predictions = np.argmax(predict_x,axis=1)\n",
    "    predictions = predict_x\n",
    "\n",
    "    df_pred = pd.DataFrame({'prediction':predictions}, index=year_data.index)\n",
    "    df_pred = df_pred.replace({-1:1, 1:-1}) # convert classes to buy hold sell\n",
    "    dates = df_pred.index\n",
    "\n",
    "    if year == 2022:\n",
    "        end_date = \"2022-09-02\"\n",
    "    else:\n",
    "        end_date = str(year+1) + \"-01-01\"\n",
    "    df_prices = yf.download(\"^GSPC\", start=dates[0], end=end_date)[['Adj Close']]\n",
    "\n",
    "    # create positions column\n",
    "    positions = []\n",
    "    prev = 0\n",
    "    for i in range(len(df_pred)):\n",
    "        if df_pred.iloc[i]['prediction'] == 0:\n",
    "            positions.append(prev)\n",
    "        else:\n",
    "            prev = df_pred.iloc[i]['prediction']\n",
    "            positions.append(prev)\n",
    "\n",
    "    df_business = pd.DataFrame()\n",
    "    df_business['stock_daily_log_return'] = np.log(df_prices /df_prices.shift(1))['Adj Close']\n",
    "    df_business['prediction'] = df_pred['prediction']\n",
    "    df_business['position'] = positions\n",
    "    df_business['benchmark'] = 1 # long and hold strategy\n",
    "    df_business[\"strategy_Returns\"] = df_business[\"stock_daily_log_return\"] * df_business[\"position\"].shift(1)\n",
    "    df_business[\"benchmark_Returns\"] = df_business[\"stock_daily_log_return\"] * df_business[\"benchmark\"].shift(1)\n",
    "\n",
    "    # Annual Mean Returns or Expected returns\n",
    "    expected_strategy_annual_return = np.exp(df_business['strategy_Returns'].mean() * 252) - 1 \n",
    "    expected_benchmark_annual_return = np.exp(df_business['benchmark_Returns'].mean() * 252) - 1 \n",
    "    business_metric_results.loc[year] = [expected_strategy_annual_return, expected_benchmark_annual_return]\n",
    "    # print(f'Expected Annual Returns: Strategy: {round(expected_strategy_annual_return*100, 2)}%  |  Stock: {round(expected_benchmark_annual_return*100, 2)}%')\n",
    "\n",
    "business_metric_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
