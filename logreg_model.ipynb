{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.0.0)/charset_normalizer (2.0.6) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "from scipy.stats import loguniform, uniform, randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_distribution = {'penalty': ['l1', 'l2'], 'C': loguniform(0.001, 100), 'solver': ['newton-cg','sag','saga','lbfgs']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3perc_lag3 = pd.read_excel(\"data/model_inputs2/x_train_3perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "X_test_3perc_lag3 = pd.read_excel(\"data/model_inputs2/x_test_3perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_train_3perc_lag3 = pd.read_excel(\"data/model_inputs2/y_train_3perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_test_3perc_lag3 = pd.read_excel(\"data/model_inputs2/y_test_3perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "\n",
    "X_train_3perc_lag7 = pd.read_excel(\"data/model_inputs2/x_train_3perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "X_test_3perc_lag7 = pd.read_excel(\"data/model_inputs2/x_test_3perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_train_3perc_lag7 = pd.read_excel(\"data/model_inputs2/y_train_3perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_test_3perc_lag7 = pd.read_excel(\"data/model_inputs2/y_test_3perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "\n",
    "X_train_5perc_lag3 = pd.read_excel(\"data/model_inputs2/x_train_5perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "X_test_5perc_lag3 = pd.read_excel(\"data/model_inputs2/x_test_5perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_train_5perc_lag3 = pd.read_excel(\"data/model_inputs2/y_train_5perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_test_5perc_lag3 = pd.read_excel(\"data/model_inputs2/y_test_5perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "\n",
    "X_train_5perc_lag7 = pd.read_excel(\"data/model_inputs2/x_train_5perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "X_test_5perc_lag7 = pd.read_excel(\"data/model_inputs2/x_test_5perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_train_5perc_lag7 = pd.read_excel(\"data/model_inputs2/y_train_5perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_test_5perc_lag7 = pd.read_excel(\"data/model_inputs2/y_test_5perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote(X_train, y_train):\n",
    "    sm = SMOTE(sampling_strategy='not majority')\n",
    "    X_train_oversampled, y_train_oversampled = sm.fit_resample(X_train, y_train)\n",
    "    return X_train_oversampled, y_train_oversampled\n",
    "\n",
    "def random_oversampler(X_train, y_train):\n",
    "    oversample = RandomOverSampler(sampling_strategy='not majority')\n",
    "    X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
    "    return X_over, y_over\n",
    "\n",
    "def adasyn(X_train, y_train):\n",
    "    ada = ADASYN(sampling_strategy = 'not majority')\n",
    "    X_resampled, y_resampled = ADASYN().fit_resample(X_train, y_train)\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 combinations without tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>perc_threshold</th>\n",
       "      <th>lag</th>\n",
       "      <th>oversampling</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>pred_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>3perc</td>\n",
       "      <td>3</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.492615</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.462147</td>\n",
       "      <td>{-1: 70, 0: 59, 1: 39}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>3perc</td>\n",
       "      <td>3</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.481255</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.475993</td>\n",
       "      <td>{-1: 55, 0: 79, 1: 34}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>3perc</td>\n",
       "      <td>3</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>0.440476</td>\n",
       "      <td>0.481883</td>\n",
       "      <td>0.440476</td>\n",
       "      <td>0.434101</td>\n",
       "      <td>{-1: 82, 0: 53, 1: 33}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>3perc</td>\n",
       "      <td>7</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.413697</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.332507</td>\n",
       "      <td>{-1: 29, 0: 43, 1: 96}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>3perc</td>\n",
       "      <td>7</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>0.327381</td>\n",
       "      <td>0.380357</td>\n",
       "      <td>0.327381</td>\n",
       "      <td>0.318608</td>\n",
       "      <td>{-1: 31, 0: 46, 1: 91}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>3perc</td>\n",
       "      <td>7</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>0.327381</td>\n",
       "      <td>0.377275</td>\n",
       "      <td>0.327381</td>\n",
       "      <td>0.318727</td>\n",
       "      <td>{-1: 46, 0: 42, 1: 80}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>3</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.720238</td>\n",
       "      <td>0.742433</td>\n",
       "      <td>0.720238</td>\n",
       "      <td>0.722882</td>\n",
       "      <td>{-1: 9, 0: 140, 1: 19}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>3</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.749008</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.765297</td>\n",
       "      <td>{-1: 9, 0: 156, 1: 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>3</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.729507</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.709673</td>\n",
       "      <td>{-1: 8, 0: 140, 1: 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.601190</td>\n",
       "      <td>0.669772</td>\n",
       "      <td>0.601190</td>\n",
       "      <td>0.628185</td>\n",
       "      <td>{-1: 1, 0: 120, 1: 47}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>0.648810</td>\n",
       "      <td>0.684398</td>\n",
       "      <td>0.648810</td>\n",
       "      <td>0.656932</td>\n",
       "      <td>{-1: 4, 0: 134, 1: 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>0.601190</td>\n",
       "      <td>0.653771</td>\n",
       "      <td>0.601190</td>\n",
       "      <td>0.623046</td>\n",
       "      <td>{0: 124, 1: 44}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model perc_threshold  lag        oversampling  accuracy  \\\n",
       "0   Logistic Regression          3perc    3               smote  0.464286   \n",
       "1   Logistic Regression          3perc    3  random_oversampler  0.476190   \n",
       "2   Logistic Regression          3perc    3              adasyn  0.440476   \n",
       "3   Logistic Regression          3perc    7               smote  0.339286   \n",
       "4   Logistic Regression          3perc    7  random_oversampler  0.327381   \n",
       "5   Logistic Regression          3perc    7              adasyn  0.327381   \n",
       "6   Logistic Regression          5perc    3               smote  0.720238   \n",
       "7   Logistic Regression          5perc    3  random_oversampler  0.803571   \n",
       "8   Logistic Regression          5perc    3              adasyn  0.708333   \n",
       "9   Logistic Regression          5perc    7               smote  0.601190   \n",
       "10  Logistic Regression          5perc    7  random_oversampler  0.648810   \n",
       "11  Logistic Regression          5perc    7              adasyn  0.601190   \n",
       "\n",
       "    precision    recall        f1              pred_count  \n",
       "0    0.492615  0.464286  0.462147  {-1: 70, 0: 59, 1: 39}  \n",
       "1    0.481255  0.476190  0.475993  {-1: 55, 0: 79, 1: 34}  \n",
       "2    0.481883  0.440476  0.434101  {-1: 82, 0: 53, 1: 33}  \n",
       "3    0.413697  0.339286  0.332507  {-1: 29, 0: 43, 1: 96}  \n",
       "4    0.380357  0.327381  0.318608  {-1: 31, 0: 46, 1: 91}  \n",
       "5    0.377275  0.327381  0.318727  {-1: 46, 0: 42, 1: 80}  \n",
       "6    0.742433  0.720238  0.722882  {-1: 9, 0: 140, 1: 19}  \n",
       "7    0.749008  0.803571  0.765297   {-1: 9, 0: 156, 1: 3}  \n",
       "8    0.729507  0.708333  0.709673  {-1: 8, 0: 140, 1: 20}  \n",
       "9    0.669772  0.601190  0.628185  {-1: 1, 0: 120, 1: 47}  \n",
       "10   0.684398  0.648810  0.656932  {-1: 4, 0: 134, 1: 30}  \n",
       "11   0.653771  0.601190  0.623046         {0: 124, 1: 44}  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_col, lag_col, oversampling_method, accuracy, precision, recall, f1, pred_count = [], [], [], [], [], [], [], []\n",
    "\n",
    "for perc in ['3perc', '5perc']:\n",
    "    for lag in [3, 7]:\n",
    "        for oversampling in ['smote', 'random_oversampler', 'adasyn']:\n",
    "            X_train = eval(f'X_train_{perc}_lag{lag}')\n",
    "            X_test = eval(f'X_test_{perc}_lag{lag}')\n",
    "            y_train = eval(f'y_train_{perc}_lag{lag}')\n",
    "            y_test = eval(f'y_test_{perc}_lag{lag}')\n",
    "\n",
    "            # oversampling\n",
    "            if oversampling == 'smote':\n",
    "                X_train_oversampled, y_train_oversampled = smote(X_train, y_train)\n",
    "            elif oversampling == 'random_oversampler':\n",
    "                X_train_oversampled, y_train_oversampled = random_oversampler(X_train, y_train)\n",
    "            else:\n",
    "                X_train_oversampled, y_train_oversampled = adasyn(X_train, y_train)\n",
    "\n",
    "            # fit and predict\n",
    "            logreg = LogisticRegression()\n",
    "            pred = logreg.fit(X_train_oversampled, y_train_oversampled).predict(X_test)\n",
    "\n",
    "            # update columns\n",
    "            perc_col.append(perc)\n",
    "            lag_col.append(lag)\n",
    "            oversampling_method.append(oversampling)\n",
    "            accuracy.append(accuracy_score(y_test, pred))\n",
    "            precision.append(precision_score(y_test, pred, average='weighted'))\n",
    "            recall.append(recall_score(y_test, pred, average='weighted'))\n",
    "            f1.append(f1_score(y_test, pred, average='weighted'))\n",
    "            pred_count.append(dict(pd.Series(pred).value_counts().sort_index()))\n",
    "\n",
    "results_no_tuning = pd.DataFrame({\n",
    "    'model': \"Logistic Regression\",\n",
    "    'perc_threshold': perc_col,\n",
    "    'lag': lag_col,\n",
    "    'oversampling': oversampling_method,\n",
    "    'accuracy': accuracy,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1': f1,\n",
    "    'pred_count': pred_count\n",
    "})\n",
    "results_no_tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning for 5perc, lag7, random_oversampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_col, lag_col, oversampling_method, param, accuracy, precision, recall, f1 = [], [], [], [], [], [], [], []\n",
    "\n",
    "perc = '5perc'\n",
    "lag = 7\n",
    "oversampling = 'random_oversampler'\n",
    "X_train = eval(f'X_train_{perc}_lag{lag}')\n",
    "X_test = eval(f'X_test_{perc}_lag{lag}')\n",
    "y_train = eval(f'y_train_{perc}_lag{lag}')\n",
    "y_test = eval(f'y_test_{perc}_lag{lag}')\n",
    "\n",
    "# oversampling\n",
    "if oversampling == 'smote':\n",
    "    X_train_oversampled, y_train_oversampled = smote(X_train, y_train)\n",
    "elif oversampling == 'random_oversampler':\n",
    "    X_train_oversampled, y_train_oversampled = random_oversampler(X_train, y_train)\n",
    "else:\n",
    "    X_train_oversampled, y_train_oversampled = adasyn(X_train, y_train)\n",
    "\n",
    "# tuning\n",
    "logreg = LogisticRegression()\n",
    "logreg_clf = RandomizedSearchCV(logreg, logreg_distribution, n_iter=100, scoring=['accuracy', 'recall_weighted', 'precision_weighted', 'f1_weighted'], refit='f1_weighted', random_state=42)\n",
    "logreg_search = logreg_clf.fit(X_train_oversampled, y_train_oversampled)\n",
    "\n",
    "# update columns\n",
    "perc_col.append([perc]*100)\n",
    "lag_col.append([lag]*100)\n",
    "oversampling_method.append([oversampling]*100)\n",
    "param.append(logreg_search.cv_results_['params'])\n",
    "accuracy.append(logreg_search.cv_results_['mean_test_accuracy'])\n",
    "precision.append(logreg_search.cv_results_['mean_test_precision_weighted'])\n",
    "recall.append(logreg_search.cv_results_['mean_test_recall_weighted'])\n",
    "f1.append(logreg_search.cv_results_['mean_test_f1_weighted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'model': \"Logistic Regression\",\n",
    "    'perc_threshold': np.array(perc_col).flatten(),\n",
    "    'lag': np.array(lag_col).flatten(),\n",
    "    'oversampling': np.array(oversampling_method).flatten(),\n",
    "    'parameters': np.array(param).flatten(),\n",
    "    'accuracy': np.array(accuracy).flatten(),\n",
    "    'precision': np.array(precision).flatten(),\n",
    "    'recall': np.array(recall).flatten(),\n",
    "    'f1': np.array(f1).flatten(),\n",
    "}).sort_values(by=\"f1\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>perc_threshold</th>\n",
       "      <th>lag</th>\n",
       "      <th>oversampling</th>\n",
       "      <th>parameters</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>{'C': 0.006026889128682509, 'penalty': 'l1', '...</td>\n",
       "      <td>0.719571</td>\n",
       "      <td>0.733531</td>\n",
       "      <td>0.719571</td>\n",
       "      <td>0.716058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>{'C': 0.001339971723117972, 'penalty': 'l1', '...</td>\n",
       "      <td>0.714689</td>\n",
       "      <td>0.732095</td>\n",
       "      <td>0.714689</td>\n",
       "      <td>0.711190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>{'C': 0.0010656401760606444, 'penalty': 'l1', ...</td>\n",
       "      <td>0.712832</td>\n",
       "      <td>0.729418</td>\n",
       "      <td>0.712832</td>\n",
       "      <td>0.709442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>{'C': 70.45683638454503, 'penalty': 'l2', 'sol...</td>\n",
       "      <td>0.668032</td>\n",
       "      <td>0.631138</td>\n",
       "      <td>0.668032</td>\n",
       "      <td>0.642208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>{'C': 4.446628955475449, 'penalty': 'l2', 'sol...</td>\n",
       "      <td>0.668033</td>\n",
       "      <td>0.631469</td>\n",
       "      <td>0.668033</td>\n",
       "      <td>0.641994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>{'C': 7.264803074826727, 'penalty': 'l2', 'sol...</td>\n",
       "      <td>0.668033</td>\n",
       "      <td>0.631331</td>\n",
       "      <td>0.668033</td>\n",
       "      <td>0.641931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>{'C': 1.146210740342503, 'penalty': 'l2', 'sol...</td>\n",
       "      <td>0.667569</td>\n",
       "      <td>0.631294</td>\n",
       "      <td>0.667569</td>\n",
       "      <td>0.641751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>{'C': 1.11640473527937, 'penalty': 'l2', 'solv...</td>\n",
       "      <td>0.667569</td>\n",
       "      <td>0.631212</td>\n",
       "      <td>0.667569</td>\n",
       "      <td>0.641718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>{'C': 3.4220529032706932, 'penalty': 'l1', 'so...</td>\n",
       "      <td>0.667801</td>\n",
       "      <td>0.631100</td>\n",
       "      <td>0.667801</td>\n",
       "      <td>0.641674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>{'C': 6.366859160799431, 'penalty': 'l2', 'sol...</td>\n",
       "      <td>0.667801</td>\n",
       "      <td>0.631054</td>\n",
       "      <td>0.667801</td>\n",
       "      <td>0.641655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model perc_threshold  lag        oversampling  \\\n",
       "0  Logistic Regression          5perc    7  random_oversampler   \n",
       "1  Logistic Regression          5perc    7  random_oversampler   \n",
       "2  Logistic Regression          5perc    7  random_oversampler   \n",
       "3  Logistic Regression          5perc    7  random_oversampler   \n",
       "4  Logistic Regression          5perc    7  random_oversampler   \n",
       "5  Logistic Regression          5perc    7  random_oversampler   \n",
       "6  Logistic Regression          5perc    7  random_oversampler   \n",
       "7  Logistic Regression          5perc    7  random_oversampler   \n",
       "8  Logistic Regression          5perc    7  random_oversampler   \n",
       "9  Logistic Regression          5perc    7  random_oversampler   \n",
       "\n",
       "                                          parameters  accuracy  precision  \\\n",
       "0  {'C': 0.006026889128682509, 'penalty': 'l1', '...  0.719571   0.733531   \n",
       "1  {'C': 0.001339971723117972, 'penalty': 'l1', '...  0.714689   0.732095   \n",
       "2  {'C': 0.0010656401760606444, 'penalty': 'l1', ...  0.712832   0.729418   \n",
       "3  {'C': 70.45683638454503, 'penalty': 'l2', 'sol...  0.668032   0.631138   \n",
       "4  {'C': 4.446628955475449, 'penalty': 'l2', 'sol...  0.668033   0.631469   \n",
       "5  {'C': 7.264803074826727, 'penalty': 'l2', 'sol...  0.668033   0.631331   \n",
       "6  {'C': 1.146210740342503, 'penalty': 'l2', 'sol...  0.667569   0.631294   \n",
       "7  {'C': 1.11640473527937, 'penalty': 'l2', 'solv...  0.667569   0.631212   \n",
       "8  {'C': 3.4220529032706932, 'penalty': 'l1', 'so...  0.667801   0.631100   \n",
       "9  {'C': 6.366859160799431, 'penalty': 'l2', 'sol...  0.667801   0.631054   \n",
       "\n",
       "     recall        f1  \n",
       "0  0.719571  0.716058  \n",
       "1  0.714689  0.711190  \n",
       "2  0.712832  0.709442  \n",
       "3  0.668032  0.642208  \n",
       "4  0.668033  0.641994  \n",
       "5  0.668033  0.641931  \n",
       "6  0.667569  0.641751  \n",
       "7  0.667569  0.641718  \n",
       "8  0.667801  0.641674  \n",
       "9  0.667801  0.641655  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.006026889128682509, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params, best_perc, best_lag, best_oversampling = results.iloc[0]['parameters'], results.iloc[0]['perc_threshold'], results.iloc[0]['lag'], results.iloc[0]['oversampling']\n",
    "best_model = LogisticRegression(**best_params)\n",
    "X_train, y_train, x_test, y_test = eval(f'X_train_{best_perc}_lag{best_lag}'), eval(f'y_train_{best_perc}_lag{best_lag}'), eval(f'X_test_{best_perc}_lag{best_lag}'), eval(f'y_test_{best_perc}_lag{best_lag}')\n",
    "\n",
    "if best_oversampling == 'smote':\n",
    "    X_train_oversampled, y_train_oversampled = smote(X_train, y_train)\n",
    "elif best_oversampling == 'random_oversampler':\n",
    "    X_train_oversampled, y_train_oversampled = random_oversampler(X_train, y_train)\n",
    "else:\n",
    "    X_train_oversampled, y_train_oversampled = adasyn(X_train, y_train)\n",
    "\n",
    "best_model.fit(X_train_oversampled, y_train_oversampled)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(actual, predictions):\n",
    "    print(f\"accuracy: {accuracy_score(actual, predictions)}\")\n",
    "    print(f\"precision: {precision_score(actual, predictions, average='weighted')}\")\n",
    "    print(f\"recall: {recall_score(actual, predictions, average='weighted')}\")\n",
    "    print(f\"f1: {f1_score(actual, predictions, average='weighted')}\")\n",
    "    print(f\"confusion matrix:\\n{confusion_matrix(actual, predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6785714285714286\n",
      "precision: 0.7302295918367346\n",
      "recall: 0.6785714285714286\n",
      "f1: 0.6933108501552796\n",
      "confusion matrix:\n",
      "[[ 12   9   0]\n",
      " [ 34 102   1]\n",
      " [  2   8   0]]\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_model.predict(X_test)\n",
    "print_results(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7623585467540203\n",
      "precision: 0.9234567003493235\n",
      "recall: 0.7623585467540203\n",
      "f1: 0.8227292220950283\n",
      "confusion matrix:\n",
      "[[  49   15    2]\n",
      " [ 200 1213  160]\n",
      " [   6   16   18]]\n"
     ]
    }
   ],
   "source": [
    "X_full = pd.concat([X_train, X_test])\n",
    "y_full = pd.concat([y_train, y_test])\n",
    "\n",
    "full_pred = best_model.predict(X_full)\n",
    "print_results(y_full, full_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Business Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1679, 11)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_df_x = pd.concat([X_train, X_test])\n",
    "whole_df_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df_x['year'] = whole_df_x.index.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp_strategy_annual_return</th>\n",
       "      <th>exp_benchmark_annual_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.164536</td>\n",
       "      <td>0.112846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>0.108954</td>\n",
       "      <td>0.185753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>-0.113091</td>\n",
       "      <td>-0.070634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>0.288443</td>\n",
       "      <td>0.288443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>-0.496283</td>\n",
       "      <td>0.152929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>0.264121</td>\n",
       "      <td>0.289230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>-0.058229</td>\n",
       "      <td>-0.249185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      exp_strategy_annual_return  exp_benchmark_annual_return\n",
       "2016                    0.164536                     0.112846\n",
       "2017                    0.108954                     0.185753\n",
       "2018                   -0.113091                    -0.070634\n",
       "2019                    0.288443                     0.288443\n",
       "2020                   -0.496283                     0.152929\n",
       "2021                    0.264121                     0.289230\n",
       "2022                   -0.058229                    -0.249185"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_metric_results = pd.DataFrame(columns=['exp_strategy_annual_return', 'exp_benchmark_annual_return'])\n",
    "\n",
    "for year in [2016, 2017, 2018, 2019, 2020, 2021, 2022]:\n",
    "    year_data = whole_df_x[whole_df_x['year'] == year]\n",
    "    # year_data = year_data.set_index('index')\n",
    "    year_data = year_data.drop(['year'], axis = 1)\n",
    "    predict_x = best_model.predict(np.array(year_data)) \n",
    "    # predictions = np.argmax(predict_x,axis=1)\n",
    "    predictions = predict_x\n",
    "\n",
    "    df_pred = pd.DataFrame({'prediction':predictions}, index=year_data.index)\n",
    "    df_pred = df_pred.replace({-1:1, 1:-1}) # convert classes to buy hold sell\n",
    "    dates = df_pred.index\n",
    "\n",
    "    if year == 2022:\n",
    "        end_date = \"2022-09-02\"\n",
    "    else:\n",
    "        end_date = str(year+1) + \"-01-01\"\n",
    "    df_prices = yf.download(\"^GSPC\", start=dates[0], end=end_date)[['Adj Close']]\n",
    "\n",
    "    # create positions column\n",
    "    positions = []\n",
    "    prev = 0\n",
    "    for i in range(len(df_pred)):\n",
    "        if df_pred.iloc[i]['prediction'] == 0:\n",
    "            positions.append(prev)\n",
    "        else:\n",
    "            prev = df_pred.iloc[i]['prediction']\n",
    "            positions.append(prev)\n",
    "\n",
    "    df_business = pd.DataFrame()\n",
    "    df_business['stock_daily_log_return'] = np.log(df_prices /df_prices.shift(1))['Adj Close']\n",
    "    df_business['prediction'] = df_pred['prediction']\n",
    "    df_business['position'] = positions\n",
    "    df_business['benchmark'] = 1 # long and hold strategy\n",
    "    df_business[\"strategy_Returns\"] = df_business[\"stock_daily_log_return\"] * df_business[\"position\"].shift(1)\n",
    "    df_business[\"benchmark_Returns\"] = df_business[\"stock_daily_log_return\"] * df_business[\"benchmark\"].shift(1)\n",
    "\n",
    "    # Annual Mean Returns or Expected returns\n",
    "    expected_strategy_annual_return = np.exp(df_business['strategy_Returns'].mean() * 252) - 1 \n",
    "    expected_benchmark_annual_return = np.exp(df_business['benchmark_Returns'].mean() * 252) - 1 \n",
    "    business_metric_results.loc[year] = [expected_strategy_annual_return, expected_benchmark_annual_return]\n",
    "    # print(f'Expected Annual Returns: Strategy: {round(expected_strategy_annual_return*100, 2)}%  |  Stock: {round(expected_benchmark_annual_return*100, 2)}%')\n",
    "\n",
    "business_metric_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
