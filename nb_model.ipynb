{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.0.0)/charset_normalizer (2.0.6) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "from scipy.stats import loguniform, uniform, randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_distribution = {'alpha':loguniform(0.001, 100)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3perc_lag3 = pd.read_excel(\"data/model_inputs2/x_train_3perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "X_test_3perc_lag3 = pd.read_excel(\"data/model_inputs2/x_test_3perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_train_3perc_lag3 = pd.read_excel(\"data/model_inputs2/y_train_3perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_test_3perc_lag3 = pd.read_excel(\"data/model_inputs2/y_test_3perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "\n",
    "X_train_3perc_lag7 = pd.read_excel(\"data/model_inputs2/x_train_3perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "X_test_3perc_lag7 = pd.read_excel(\"data/model_inputs2/x_test_3perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_train_3perc_lag7 = pd.read_excel(\"data/model_inputs2/y_train_3perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_test_3perc_lag7 = pd.read_excel(\"data/model_inputs2/y_test_3perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "\n",
    "X_train_5perc_lag3 = pd.read_excel(\"data/model_inputs2/x_train_5perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "X_test_5perc_lag3 = pd.read_excel(\"data/model_inputs2/x_test_5perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_train_5perc_lag3 = pd.read_excel(\"data/model_inputs2/y_train_5perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_test_5perc_lag3 = pd.read_excel(\"data/model_inputs2/y_test_5perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "\n",
    "X_train_5perc_lag7 = pd.read_excel(\"data/model_inputs2/x_train_5perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "X_test_5perc_lag7 = pd.read_excel(\"data/model_inputs2/x_test_5perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_train_5perc_lag7 = pd.read_excel(\"data/model_inputs2/y_train_5perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_test_5perc_lag7 = pd.read_excel(\"data/model_inputs2/y_test_5perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote(X_train, y_train):\n",
    "    sm = SMOTE(sampling_strategy='not majority')\n",
    "    X_train_oversampled, y_train_oversampled = sm.fit_resample(X_train, y_train)\n",
    "    return X_train_oversampled, y_train_oversampled\n",
    "\n",
    "def random_oversampler(X_train, y_train):\n",
    "    oversample = RandomOverSampler(sampling_strategy='not majority')\n",
    "    X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
    "    return X_over, y_over\n",
    "\n",
    "def adasyn(X_train, y_train):\n",
    "    ada = ADASYN(sampling_strategy = 'not majority')\n",
    "    X_resampled, y_resampled = ADASYN().fit_resample(X_train, y_train)\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 combinations without tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>perc_threshold</th>\n",
       "      <th>lag</th>\n",
       "      <th>oversampling</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>pred_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB</td>\n",
       "      <td>3perc</td>\n",
       "      <td>3</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.470238</td>\n",
       "      <td>0.394611</td>\n",
       "      <td>0.470238</td>\n",
       "      <td>0.410436</td>\n",
       "      <td>{-1: 40, 0: 122, 1: 6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB</td>\n",
       "      <td>3perc</td>\n",
       "      <td>3</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.386523</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.401967</td>\n",
       "      <td>{-1: 39, 0: 117, 1: 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB</td>\n",
       "      <td>3perc</td>\n",
       "      <td>3</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>0.488095</td>\n",
       "      <td>0.369860</td>\n",
       "      <td>0.488095</td>\n",
       "      <td>0.419740</td>\n",
       "      <td>{-1: 47, 0: 120, 1: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB</td>\n",
       "      <td>3perc</td>\n",
       "      <td>7</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.395025</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.403149</td>\n",
       "      <td>{-1: 45, 0: 118, 1: 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NB</td>\n",
       "      <td>3perc</td>\n",
       "      <td>7</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.414289</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.409659</td>\n",
       "      <td>{-1: 43, 0: 118, 1: 7}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NB</td>\n",
       "      <td>3perc</td>\n",
       "      <td>7</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>0.367125</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>0.416620</td>\n",
       "      <td>{-1: 52, 0: 116}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NB</td>\n",
       "      <td>5perc</td>\n",
       "      <td>3</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.720238</td>\n",
       "      <td>0.687208</td>\n",
       "      <td>0.720238</td>\n",
       "      <td>0.703244</td>\n",
       "      <td>{-1: 25, 0: 143}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NB</td>\n",
       "      <td>5perc</td>\n",
       "      <td>3</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>0.744048</td>\n",
       "      <td>0.691707</td>\n",
       "      <td>0.744048</td>\n",
       "      <td>0.716830</td>\n",
       "      <td>{-1: 20, 0: 148}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NB</td>\n",
       "      <td>5perc</td>\n",
       "      <td>3</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>0.726190</td>\n",
       "      <td>0.685368</td>\n",
       "      <td>0.726190</td>\n",
       "      <td>0.705183</td>\n",
       "      <td>{-1: 23, 0: 145}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NB</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>smote</td>\n",
       "      <td>0.755952</td>\n",
       "      <td>0.703467</td>\n",
       "      <td>0.755952</td>\n",
       "      <td>0.728650</td>\n",
       "      <td>{-1: 20, 0: 148}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NB</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.696427</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.716648</td>\n",
       "      <td>{-1: 23, 0: 145}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NB</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>0.779762</td>\n",
       "      <td>0.717654</td>\n",
       "      <td>0.779762</td>\n",
       "      <td>0.745795</td>\n",
       "      <td>{-1: 15, 0: 152, 1: 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model perc_threshold  lag        oversampling  accuracy  precision  \\\n",
       "0     NB          3perc    3               smote  0.470238   0.394611   \n",
       "1     NB          3perc    3  random_oversampler  0.446429   0.386523   \n",
       "2     NB          3perc    3              adasyn  0.488095   0.369860   \n",
       "3     NB          3perc    7               smote  0.458333   0.395025   \n",
       "4     NB          3perc    7  random_oversampler  0.458333   0.414289   \n",
       "5     NB          3perc    7              adasyn  0.482143   0.367125   \n",
       "6     NB          5perc    3               smote  0.720238   0.687208   \n",
       "7     NB          5perc    3  random_oversampler  0.744048   0.691707   \n",
       "8     NB          5perc    3              adasyn  0.726190   0.685368   \n",
       "9     NB          5perc    7               smote  0.755952   0.703467   \n",
       "10    NB          5perc    7  random_oversampler  0.738095   0.696427   \n",
       "11    NB          5perc    7              adasyn  0.779762   0.717654   \n",
       "\n",
       "      recall        f1               pred_count  \n",
       "0   0.470238  0.410436   {-1: 40, 0: 122, 1: 6}  \n",
       "1   0.446429  0.401967  {-1: 39, 0: 117, 1: 12}  \n",
       "2   0.488095  0.419740   {-1: 47, 0: 120, 1: 1}  \n",
       "3   0.458333  0.403149   {-1: 45, 0: 118, 1: 5}  \n",
       "4   0.458333  0.409659   {-1: 43, 0: 118, 1: 7}  \n",
       "5   0.482143  0.416620         {-1: 52, 0: 116}  \n",
       "6   0.720238  0.703244         {-1: 25, 0: 143}  \n",
       "7   0.744048  0.716830         {-1: 20, 0: 148}  \n",
       "8   0.726190  0.705183         {-1: 23, 0: 145}  \n",
       "9   0.755952  0.728650         {-1: 20, 0: 148}  \n",
       "10  0.738095  0.716648         {-1: 23, 0: 145}  \n",
       "11  0.779762  0.745795   {-1: 15, 0: 152, 1: 1}  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_col, lag_col, oversampling_method, accuracy, precision, recall, f1, pred_count = [], [], [], [], [], [], [], []\n",
    "\n",
    "for perc in ['3perc', '5perc']:\n",
    "    for lag in [3, 7]:\n",
    "        for oversampling in ['smote', 'random_oversampler', 'adasyn']:\n",
    "            X_train = eval(f'X_train_{perc}_lag{lag}')\n",
    "            X_test = eval(f'X_test_{perc}_lag{lag}')\n",
    "            y_train = eval(f'y_train_{perc}_lag{lag}')\n",
    "            y_test = eval(f'y_test_{perc}_lag{lag}')\n",
    "\n",
    "            # oversampling\n",
    "            if oversampling == 'smote':\n",
    "                X_train_oversampled, y_train_oversampled = smote(X_train, y_train)\n",
    "            elif oversampling == 'random_oversampler':\n",
    "                X_train_oversampled, y_train_oversampled = random_oversampler(X_train, y_train)\n",
    "            else:\n",
    "                X_train_oversampled, y_train_oversampled = adasyn(X_train, y_train)\n",
    "\n",
    "            # scaling for Naive Bayes\n",
    "            scaler = MinMaxScaler()\n",
    "            X_train_oversampled = scaler.fit_transform(X_train_oversampled)\n",
    "            X_test = scaler.transform(X_test)\n",
    "            \n",
    "            # fit and predict\n",
    "            nb = MultinomialNB()\n",
    "            pred = nb.fit(X_train_oversampled, y_train_oversampled).predict(X_test)\n",
    "\n",
    "            # update columns\n",
    "            perc_col.append(perc)\n",
    "            lag_col.append(lag)\n",
    "            oversampling_method.append(oversampling)\n",
    "            accuracy.append(accuracy_score(y_test, pred))\n",
    "            precision.append(precision_score(y_test, pred, average='weighted'))\n",
    "            recall.append(recall_score(y_test, pred, average='weighted'))\n",
    "            f1.append(f1_score(y_test, pred, average='weighted'))\n",
    "            pred_count.append(dict(pd.Series(pred).value_counts().sort_index()))\n",
    "\n",
    "results_no_tuning = pd.DataFrame({\n",
    "    'model': \"NB\",\n",
    "    'perc_threshold': perc_col,\n",
    "    'lag': lag_col,\n",
    "    'oversampling': oversampling_method,\n",
    "    'accuracy': accuracy,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1': f1,\n",
    "    'pred_count': pred_count\n",
    "})\n",
    "results_no_tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning for 5perc, lag7 and adasyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_col, lag_col, oversampling_method, param, accuracy, precision, recall, f1 = [], [], [], [], [], [], [], []\n",
    "\n",
    "# best perc, lag and oversampling method\n",
    "perc = '5perc'\n",
    "lag = 7\n",
    "oversampling = 'adasyn'\n",
    "X_train = eval(f'X_train_{perc}_lag{lag}')\n",
    "X_test = eval(f'X_test_{perc}_lag{lag}')\n",
    "y_train = eval(f'y_train_{perc}_lag{lag}')\n",
    "y_test = eval(f'y_test_{perc}_lag{lag}')\n",
    "\n",
    "# oversampling\n",
    "if oversampling == 'smote':\n",
    "    X_train_oversampled, y_train_oversampled = smote(X_train, y_train)\n",
    "elif oversampling == 'random_oversampler':\n",
    "    X_train_oversampled, y_train_oversampled = random_oversampler(X_train, y_train)\n",
    "else:\n",
    "    X_train_oversampled, y_train_oversampled = adasyn(X_train, y_train)\n",
    "\n",
    "# scaling for Naive Bayes\n",
    "scaler = MinMaxScaler()\n",
    "X_train_oversampled = scaler.fit_transform(X_train_oversampled)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# tuning\n",
    "nb = MultinomialNB()\n",
    "lgbm_clf = RandomizedSearchCV(nb, nb_distribution, n_iter=100, scoring=['accuracy', 'recall_weighted', 'precision_weighted', 'f1_weighted'], refit='f1_weighted', random_state=42)\n",
    "lgbm_search = lgbm_clf.fit(X_train_oversampled, y_train_oversampled)\n",
    "\n",
    "# update columns\n",
    "perc_col.append([perc]*100)\n",
    "lag_col.append([lag]*100)\n",
    "oversampling_method.append([oversampling]*100)\n",
    "param.append(lgbm_search.cv_results_['params'])\n",
    "accuracy.append(lgbm_search.cv_results_['mean_test_accuracy'])\n",
    "precision.append(lgbm_search.cv_results_['mean_test_precision_weighted'])\n",
    "recall.append(lgbm_search.cv_results_['mean_test_recall_weighted'])\n",
    "f1.append(lgbm_search.cv_results_['mean_test_f1_weighted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'model': \"NB\",\n",
    "    'perc_threshold': np.array(perc_col).flatten(),\n",
    "    'lag': np.array(lag_col).flatten(),\n",
    "    'oversampling': np.array(oversampling_method).flatten(),\n",
    "    'parameters': np.array(param).flatten(),\n",
    "    'accuracy': np.array(accuracy).flatten(),\n",
    "    'precision': np.array(precision).flatten(),\n",
    "    'recall': np.array(recall).flatten(),\n",
    "    'f1': np.array(f1).flatten(),\n",
    "}).sort_values(by=\"f1\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>perc_threshold</th>\n",
       "      <th>lag</th>\n",
       "      <th>oversampling</th>\n",
       "      <th>parameters</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>{'alpha': 85.98737339212275}</td>\n",
       "      <td>0.673122</td>\n",
       "      <td>0.738358</td>\n",
       "      <td>0.673122</td>\n",
       "      <td>0.643717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>{'alpha': 70.45683638454503}</td>\n",
       "      <td>0.671729</td>\n",
       "      <td>0.737399</td>\n",
       "      <td>0.671729</td>\n",
       "      <td>0.642117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>{'alpha': 70.72114131472235}</td>\n",
       "      <td>0.671729</td>\n",
       "      <td>0.737399</td>\n",
       "      <td>0.671729</td>\n",
       "      <td>0.642117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>{'alpha': 67.32248920775338}</td>\n",
       "      <td>0.671496</td>\n",
       "      <td>0.737277</td>\n",
       "      <td>0.671496</td>\n",
       "      <td>0.641981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NB</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>{'alpha': 56.69849511478852}</td>\n",
       "      <td>0.670102</td>\n",
       "      <td>0.736149</td>\n",
       "      <td>0.670102</td>\n",
       "      <td>0.640930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NB</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>{'alpha': 55.517216852447234}</td>\n",
       "      <td>0.669869</td>\n",
       "      <td>0.735960</td>\n",
       "      <td>0.669869</td>\n",
       "      <td>0.640642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NB</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>{'alpha': 49.83043837494908}</td>\n",
       "      <td>0.668706</td>\n",
       "      <td>0.735199</td>\n",
       "      <td>0.668706</td>\n",
       "      <td>0.639488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NB</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>{'alpha': 40.679084943595456}</td>\n",
       "      <td>0.666847</td>\n",
       "      <td>0.734030</td>\n",
       "      <td>0.666847</td>\n",
       "      <td>0.637282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NB</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>{'alpha': 35.20481045526037}</td>\n",
       "      <td>0.666150</td>\n",
       "      <td>0.733274</td>\n",
       "      <td>0.666150</td>\n",
       "      <td>0.636318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NB</td>\n",
       "      <td>5perc</td>\n",
       "      <td>7</td>\n",
       "      <td>adasyn</td>\n",
       "      <td>{'alpha': 29.794544625913627}</td>\n",
       "      <td>0.664755</td>\n",
       "      <td>0.732017</td>\n",
       "      <td>0.664755</td>\n",
       "      <td>0.634936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model perc_threshold  lag oversampling                     parameters  \\\n",
       "0    NB          5perc    7       adasyn   {'alpha': 85.98737339212275}   \n",
       "1    NB          5perc    7       adasyn   {'alpha': 70.45683638454503}   \n",
       "2    NB          5perc    7       adasyn   {'alpha': 70.72114131472235}   \n",
       "3    NB          5perc    7       adasyn   {'alpha': 67.32248920775338}   \n",
       "4    NB          5perc    7       adasyn   {'alpha': 56.69849511478852}   \n",
       "5    NB          5perc    7       adasyn  {'alpha': 55.517216852447234}   \n",
       "6    NB          5perc    7       adasyn   {'alpha': 49.83043837494908}   \n",
       "7    NB          5perc    7       adasyn  {'alpha': 40.679084943595456}   \n",
       "8    NB          5perc    7       adasyn   {'alpha': 35.20481045526037}   \n",
       "9    NB          5perc    7       adasyn  {'alpha': 29.794544625913627}   \n",
       "\n",
       "   accuracy  precision    recall        f1  \n",
       "0  0.673122   0.738358  0.673122  0.643717  \n",
       "1  0.671729   0.737399  0.671729  0.642117  \n",
       "2  0.671729   0.737399  0.671729  0.642117  \n",
       "3  0.671496   0.737277  0.671496  0.641981  \n",
       "4  0.670102   0.736149  0.670102  0.640930  \n",
       "5  0.669869   0.735960  0.669869  0.640642  \n",
       "6  0.668706   0.735199  0.668706  0.639488  \n",
       "7  0.666847   0.734030  0.666847  0.637282  \n",
       "8  0.666150   0.733274  0.666150  0.636318  \n",
       "9  0.664755   0.732017  0.664755  0.634936  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=85.98737339212275)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params, best_perc, best_lag, best_oversampling = results.iloc[0]['parameters'], results.iloc[0]['perc_threshold'], results.iloc[0]['lag'], results.iloc[0]['oversampling']\n",
    "best_model = MultinomialNB(**best_params)\n",
    "X_train, y_train, x_test, y_test = eval(f'X_train_{best_perc}_lag{best_lag}'), eval(f'y_train_{best_perc}_lag{best_lag}'), eval(f'X_test_{best_perc}_lag{best_lag}'), eval(f'y_test_{best_perc}_lag{best_lag}')\n",
    "\n",
    "# scaling for Naive Bayes\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "if best_oversampling == 'smote':\n",
    "    X_train_oversampled, y_train_oversampled = smote(X_train, y_train)\n",
    "elif best_oversampling == 'random_oversampler':\n",
    "    X_train_oversampled, y_train_oversampled = random_oversampler(X_train, y_train)\n",
    "else:\n",
    "    X_train_oversampled, y_train_oversampled = adasyn(X_train, y_train)\n",
    "\n",
    "best_model.fit(X_train_oversampled, y_train_oversampled)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(actual, predictions):\n",
    "    print(f\"accuracy: {accuracy_score(actual, predictions)}\")\n",
    "    print(f\"precision: {precision_score(actual, predictions, average='weighted')}\")\n",
    "    print(f\"recall: {recall_score(actual, predictions, average='weighted')}\")\n",
    "    print(f\"f1: {f1_score(actual, predictions, average='weighted')}\")\n",
    "    print(f\"confusion matrix:\\n{confusion_matrix(actual, predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8154761904761905\n",
      "precision: 0.6650014172335601\n",
      "recall: 0.8154761904761905\n",
      "f1: 0.7325917252146761\n",
      "confusion matrix:\n",
      "[[  0  21   0]\n",
      " [  0 137   0]\n",
      " [  0  10   0]]\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_model.predict(X_test)\n",
    "print_results(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6700416914830256\n",
      "precision: 0.9135879820278063\n",
      "recall: 0.6700416914830256\n",
      "f1: 0.7575919429438953\n",
      "confusion matrix:\n",
      "[[  42   22    2]\n",
      " [ 313 1065  195]\n",
      " [   9   13   18]]\n"
     ]
    }
   ],
   "source": [
    "X_full = np.vstack([X_train, X_test])\n",
    "y_full = pd.concat([y_train, y_test])\n",
    "\n",
    "full_pred = best_model.predict(X_full)\n",
    "print_results(y_full, full_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Business Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(data=X_train, columns=X_train_3perc_lag3.columns, index=X_train_3perc_lag3.index)\n",
    "X_test_df = pd.DataFrame(data=X_test, columns=X_test_3perc_lag3.columns, index=X_test_3perc_lag3.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1679, 11)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_df_x = pd.concat([X_train_df, X_test_df])\n",
    "whole_df_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df_x['year'] = whole_df_x.index.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp_strategy_annual_return</th>\n",
       "      <th>exp_benchmark_annual_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>0.042123</td>\n",
       "      <td>0.112846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>0.131417</td>\n",
       "      <td>0.185753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>-0.093125</td>\n",
       "      <td>-0.070634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>0.288443</td>\n",
       "      <td>0.288443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>-0.499854</td>\n",
       "      <td>0.152929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>-0.224343</td>\n",
       "      <td>0.289230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.249185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      exp_strategy_annual_return  exp_benchmark_annual_return\n",
       "2016                    0.042123                     0.112846\n",
       "2017                    0.131417                     0.185753\n",
       "2018                   -0.093125                    -0.070634\n",
       "2019                    0.288443                     0.288443\n",
       "2020                   -0.499854                     0.152929\n",
       "2021                   -0.224343                     0.289230\n",
       "2022                    0.000000                    -0.249185"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_metric_results = pd.DataFrame(columns=['exp_strategy_annual_return', 'exp_benchmark_annual_return'])\n",
    "\n",
    "for year in [2016, 2017, 2018, 2019, 2020, 2021, 2022]:\n",
    "    year_data = whole_df_x[whole_df_x['year'] == year]\n",
    "    # year_data = year_data.set_index('index')\n",
    "    year_data = year_data.drop(['year'], axis = 1)\n",
    "    predict_x = best_model.predict(np.array(year_data)) \n",
    "    # predictions = np.argmax(predict_x,axis=1)\n",
    "    predictions = predict_x\n",
    "\n",
    "    df_pred = pd.DataFrame({'prediction':predictions}, index=year_data.index)\n",
    "    df_pred = df_pred.replace({-1:1, 1:-1}) # convert classes to buy hold sell\n",
    "    dates = df_pred.index\n",
    "\n",
    "    if year == 2022:\n",
    "        end_date = \"2022-09-02\"\n",
    "    else:\n",
    "        end_date = str(year+1) + \"-01-01\"\n",
    "    df_prices = yf.download(\"^GSPC\", start=dates[0], end=end_date)[['Adj Close']]\n",
    "\n",
    "    # create positions column\n",
    "    positions = []\n",
    "    prev = 0\n",
    "    for i in range(len(df_pred)):\n",
    "        if df_pred.iloc[i]['prediction'] == 0:\n",
    "            positions.append(prev)\n",
    "        else:\n",
    "            prev = df_pred.iloc[i]['prediction']\n",
    "            positions.append(prev)\n",
    "\n",
    "    df_business = pd.DataFrame()\n",
    "    df_business['stock_daily_log_return'] = np.log(df_prices /df_prices.shift(1))['Adj Close']\n",
    "    df_business['prediction'] = df_pred['prediction']\n",
    "    df_business['position'] = positions\n",
    "    df_business['benchmark'] = 1 # long and hold strategy\n",
    "    df_business[\"strategy_Returns\"] = df_business[\"stock_daily_log_return\"] * df_business[\"position\"].shift(1)\n",
    "    df_business[\"benchmark_Returns\"] = df_business[\"stock_daily_log_return\"] * df_business[\"benchmark\"].shift(1)\n",
    "\n",
    "    # Annual Mean Returns or Expected returns\n",
    "    expected_strategy_annual_return = np.exp(df_business['strategy_Returns'].mean() * 252) - 1 \n",
    "    expected_benchmark_annual_return = np.exp(df_business['benchmark_Returns'].mean() * 252) - 1 \n",
    "    business_metric_results.loc[year] = [expected_strategy_annual_return, expected_benchmark_annual_return]\n",
    "    # print(f'Expected Annual Returns: Strategy: {round(expected_strategy_annual_return*100, 2)}%  |  Stock: {round(expected_benchmark_annual_return*100, 2)}%')\n",
    "\n",
    "business_metric_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
