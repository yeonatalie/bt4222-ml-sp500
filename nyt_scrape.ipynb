{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yanytapi import SearchAPI\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_dict = {\n",
    "    'S&P': ['S. P.', 'Wall Street', 'Fed', 'Federal Reserve'],\n",
    "    'AAPL': ['Apple'],\n",
    "    'MSFT': ['Microsoft'],\n",
    "    'AMZN': ['Amazon'],\n",
    "    'TSLA': ['Tesla'],\n",
    "    'GOOGL': ['Alphabet', 'Google', 'GOOG'],\n",
    "    'BRK.B': ['Berkshire Hathaway', 'BRK'],\n",
    "    'UNH': ['UnitedHealth'],\n",
    "    'JNJ': ['Johnson', 'JnJ'],\n",
    "    'XOM': ['ExxonMobil', 'Exxon'],\n",
    "    'JPM': ['JP Morgan', 'JPMorgan'],\n",
    "    'META': ['Meta', 'Facebook'],\n",
    "    'NVDA': ['NVIDIA'],\n",
    "    'PG': ['Procter'], \n",
    "    'V': ['Visa'],\n",
    "    'HD': ['Home Depot'],\n",
    "    'CVX': ['Chevron Corporation'],\n",
    "    'MA': ['Mastercard'],\n",
    "    'PFE': ['Pfizer'],\n",
    "    'ABBV': ['AbbVie'],\n",
    "    'BAC': ['Bank of America'],\n",
    "    'LLY': ['Eli Lilly and Company'],\n",
    "    'KO': ['Coca-Cola'],\n",
    "    'PEP': ['PepsiCo', 'Pepsi'],\n",
    "    'COST': ['Costco'],\n",
    "    'MRK': ['Merck'], \n",
    "    'TMO': ['Thermo Fisher', 'Thermo Fisher Scientific'],\n",
    "    'AVGO': ['Broadcom'],\n",
    "    'DIS': ['Walt Disney'],\n",
    "    'WMT': ['Walmart'],\n",
    "    'MCD': ['McDonald\\'s'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = SearchAPI(\"RXkqQPmyy2JObRlC0qFYQj2vNxtX4oxP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### MCD ###\n",
      "McDonald's: 1000\n"
     ]
    }
   ],
   "source": [
    "dates = []\n",
    "keywords = []\n",
    "headlines = []\n",
    "abstracts = []\n",
    "lead_paragraph = []\n",
    "sections = []\n",
    "hits = []\n",
    "word_counts = []\n",
    "\n",
    "for company, keyword_list in keyword_dict.items():\n",
    "    print(f'### {company} ###')\n",
    "    for keyword in keyword_list:\n",
    "        count = 0\n",
    "        articles = api.search(keyword, fq={\"body\": keyword, \"source\": [\"Reuters\",\"AP\",\"The New York Times\"]},\n",
    "                        begin_date=\"20190101\",\n",
    "                        end_date = \"20220901\",\n",
    "                        facet_field=[\"source\", \"day_of_week\"],\n",
    "                        facet_filter=True)\n",
    "        \n",
    "        for item in articles:\n",
    "            relevant = False\n",
    "            if (count % 100 == 0):\n",
    "                time.sleep(2)\n",
    "\n",
    "            # Filtering for S&P\n",
    "            if keyword == 'S. P.':\n",
    "                sp_keywords = [\"s&p\", \"s.&p.\", \"standard & poor\", \"stock\", \"index\", \"market\"]\n",
    "                for kw in sp_keywords:\n",
    "                    if kw in item.headline[\"main\"].lower() or kw in item.abstract.lower():\n",
    "                        relevant = True\n",
    "                        break\n",
    "            else:\n",
    "                relevant = True\n",
    "\n",
    "            if relevant:\n",
    "                count += 1\n",
    "                dates.append(datetime.strptime(item.pub_date[:10], '%Y-%m-%d'))\n",
    "                keywords.append(keyword)\n",
    "                headlines.append(item.headline[\"main\"])\n",
    "                abstracts.append(item.abstract)\n",
    "                lead_paragraph.append(item.lead_paragraph)\n",
    "                sections.append(item.section_name)\n",
    "                hits.append(item.meta.hits)\n",
    "                word_counts.append(item.word_count)\n",
    "        print(f'{keyword}: {count}')\n",
    "    \n",
    "    df = pd.DataFrame({'date': dates, 'keyword': keywords, 'headline': headlines, 'abstract': abstracts, 'lead_paragraph':lead_paragraph, 'section': sections, 'hits': hits, 'word_count': word_counts})\n",
    "    df.set_index('date', inplace=True)\n",
    "    df = df.sort_index()\n",
    "\n",
    "    df.to_excel('nyt_2019_2022_raw_data_mcd.xlsx')\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(df_no_duplicate.groupby('date').count()['headline'])\n",
    "temp = temp.rename(columns={'headline': 'article_count'})\n",
    "temp = temp.reindex(pd.date_range(start=\"2019-01-01\", end=\"2022-09-01\"))\n",
    "temp = temp.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_no_duplicate.reset_index()\n",
    "test[test['date'] == '2020-01-18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[temp['article_count']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.sort_values('article_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # combine all files\n",
    "# df1 = pd.read_excel('nyt_2019_2022_subset_tillNVDA.xlsx')\n",
    "# df2 = pd.read_excel('nyt_2019_2022_subset_Visa_Costco.xlsx')\n",
    "# df3 = pd.read_excel('nyt_2019_2022_subset_Thermo_Mcd.xlsx')\n",
    "# df4 = pd.read_excel('nyt_2019_2022_subset_Procter_Merck.xlsx')\n",
    "\n",
    "# inv_dict = {}\n",
    "# for k, v_list in keyword_dict.items():\n",
    "#     for v in v_list:\n",
    "#         inv_dict[v] = k\n",
    "\n",
    "# final_df = pd.concat([df1, df2, df3, df4])\n",
    "# final_df.set_index('date', inplace=True)\n",
    "# final_df = final_df.sort_index()\n",
    "# final_df = final_df.drop_duplicates(subset=['headline'])\n",
    "# final_df['stock'] = [inv_dict[keyword] for keyword in final_df['keyword']]\n",
    "# final_df.reset_index()\n",
    "# final_df.to_excel('nyt_2019_2022.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019_2022 = pd.read_excel('nyt_2019_2022_body.xlsx')\n",
    "df_2016_2018 = pd.read_excel('nyt_2016_2018_body_no_duplicate.xlsx').drop('Unnamed: 0', axis=1)\n",
    "df = pd.concat([df_2016_2018, df_2019_2022])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows filtered: 9797\n",
      "rows left: 21851\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[df['section'].isin(['Blogs', 'Business Day', 'Opinion', 'Technology', 'The Upshot', 'U.S.', 'New York', 'World'])]\n",
    "print(f'rows filtered: {len(df) - len(filtered_df)}')\n",
    "print(f'rows left: {len(filtered_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(filtered_df.groupby('date').count()['headline'])\n",
    "temp = temp.rename(columns={'headline': 'article_count'})\n",
    "temp = temp.reindex(pd.date_range(start=\"2016-01-01\", end=\"2022-09-01\"))\n",
    "temp = temp.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 articles: 10\n",
      "<5 articles: 503\n"
     ]
    }
   ],
   "source": [
    "zero = len(temp[temp['article_count']==0])\n",
    "print(f'0 articles: {zero}')\n",
    "\n",
    "less_five = len(temp[temp['article_count']<5])\n",
    "print(f'<5 articles: {less_five}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_excel('nyt_body_filtered_sections.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('nyt_2016_2022_new.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>date</th>\n",
       "      <th>keyword</th>\n",
       "      <th>headline</th>\n",
       "      <th>abstract</th>\n",
       "      <th>lead_paragraph</th>\n",
       "      <th>section</th>\n",
       "      <th>hits</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>['Microsoft', 'Tesla']</td>\n",
       "      <td>Looking Beyond the Internet of Things</td>\n",
       "      <td>Adam Bosworth, a tech pioneer, sees the future...</td>\n",
       "      <td>SAN FRANCISCO â€” If you have sent email on Goog...</td>\n",
       "      <td>Technology</td>\n",
       "      <td>1259</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>[\"McDonald's\"]</td>\n",
       "      <td>No More Statutes of Limitations for Rape</td>\n",
       "      <td>Bill Cosby came close to escaping sexual assau...</td>\n",
       "      <td>THIS week, Bill Cosby was charged with three c...</td>\n",
       "      <td>Opinion</td>\n",
       "      <td>1514</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>['Visa']</td>\n",
       "      <td>U.S. Doesnâ€™t Know How Many Foreign Visitors Ov...</td>\n",
       "      <td>After two decades of failed attempts to track ...</td>\n",
       "      <td>WASHINGTON â€” The question from the congressman...</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>2394</td>\n",
       "      <td>1189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>['Fed']</td>\n",
       "      <td>Making And Using Models</td>\n",
       "      <td>Itâ€™s about self-discipline.</td>\n",
       "      <td>Larry Summers, Brad DeLong, and yours truly ar...</td>\n",
       "      <td>Opinion</td>\n",
       "      <td>3998</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>['Amazon']</td>\n",
       "      <td>Cutting the Cord and Feeling Good About It</td>\n",
       "      <td>Canceling cable has meant becoming more intent...</td>\n",
       "      <td>Nearly three years ago, when I first thought a...</td>\n",
       "      <td>Opinion</td>\n",
       "      <td>6215</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18734</th>\n",
       "      <td>9564</td>\n",
       "      <td>22952</td>\n",
       "      <td>2022-08-02</td>\n",
       "      <td>[\"McDonald's\"]</td>\n",
       "      <td>Starbucks Reports Record Revenue, Driven Mostl...</td>\n",
       "      <td>The largest coffee chain in the world said it ...</td>\n",
       "      <td>Customers flocking to Starbucks and ordering P...</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>1849</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18735</th>\n",
       "      <td>9565</td>\n",
       "      <td>22956</td>\n",
       "      <td>2022-08-11</td>\n",
       "      <td>[\"McDonald's\"]</td>\n",
       "      <td>The Golden Arches Return to Ukraine After a 6-...</td>\n",
       "      <td>McDonaldâ€™s said it would begin reopening store...</td>\n",
       "      <td>McDonaldâ€™s will begin reopening its restaurant...</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>1849</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18736</th>\n",
       "      <td>9566</td>\n",
       "      <td>22958</td>\n",
       "      <td>2022-08-15</td>\n",
       "      <td>[\"McDonald's\"]</td>\n",
       "      <td>The Two Simple Edicts of Successful Addiction ...</td>\n",
       "      <td>In the opioid epidemic, citizens step in to he...</td>\n",
       "      <td>HICKORY, N.C. â€” On a chilly spring evening in ...</td>\n",
       "      <td>Opinion</td>\n",
       "      <td>1849</td>\n",
       "      <td>2171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18737</th>\n",
       "      <td>9567</td>\n",
       "      <td>22961</td>\n",
       "      <td>2022-08-22</td>\n",
       "      <td>[\"McDonald's\"]</td>\n",
       "      <td>Under Pressure, McDonaldâ€™s Shakes Up Its Board</td>\n",
       "      <td>The fast-food chain has wrestled with some sha...</td>\n",
       "      <td>McDonaldâ€™s announced a shake-up of its board o...</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>1849</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18738</th>\n",
       "      <td>9568</td>\n",
       "      <td>22964</td>\n",
       "      <td>2022-08-29</td>\n",
       "      <td>[\"McDonald's\"]</td>\n",
       "      <td>California Senate Passes Bill to Regulate Fast...</td>\n",
       "      <td>If signed by Gov. Gavin Newsom, the measure wo...</td>\n",
       "      <td>The California State Senate passed a bill on M...</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>1849</td>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18739 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Unnamed: 0.1       date                 keyword  \\\n",
       "0               0             3 2016-01-01  ['Microsoft', 'Tesla']   \n",
       "1               1            10 2016-01-01          [\"McDonald's\"]   \n",
       "2               2            11 2016-01-01                ['Visa']   \n",
       "3               3            12 2016-01-02                 ['Fed']   \n",
       "4               4            15 2016-01-02              ['Amazon']   \n",
       "...           ...           ...        ...                     ...   \n",
       "18734        9564         22952 2022-08-02          [\"McDonald's\"]   \n",
       "18735        9565         22956 2022-08-11          [\"McDonald's\"]   \n",
       "18736        9566         22958 2022-08-15          [\"McDonald's\"]   \n",
       "18737        9567         22961 2022-08-22          [\"McDonald's\"]   \n",
       "18738        9568         22964 2022-08-29          [\"McDonald's\"]   \n",
       "\n",
       "                                                headline  \\\n",
       "0                  Looking Beyond the Internet of Things   \n",
       "1               No More Statutes of Limitations for Rape   \n",
       "2      U.S. Doesnâ€™t Know How Many Foreign Visitors Ov...   \n",
       "3                                Making And Using Models   \n",
       "4             Cutting the Cord and Feeling Good About It   \n",
       "...                                                  ...   \n",
       "18734  Starbucks Reports Record Revenue, Driven Mostl...   \n",
       "18735  The Golden Arches Return to Ukraine After a 6-...   \n",
       "18736  The Two Simple Edicts of Successful Addiction ...   \n",
       "18737     Under Pressure, McDonaldâ€™s Shakes Up Its Board   \n",
       "18738  California Senate Passes Bill to Regulate Fast...   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      Adam Bosworth, a tech pioneer, sees the future...   \n",
       "1      Bill Cosby came close to escaping sexual assau...   \n",
       "2      After two decades of failed attempts to track ...   \n",
       "3                            Itâ€™s about self-discipline.   \n",
       "4      Canceling cable has meant becoming more intent...   \n",
       "...                                                  ...   \n",
       "18734  The largest coffee chain in the world said it ...   \n",
       "18735  McDonaldâ€™s said it would begin reopening store...   \n",
       "18736  In the opioid epidemic, citizens step in to he...   \n",
       "18737  The fast-food chain has wrestled with some sha...   \n",
       "18738  If signed by Gov. Gavin Newsom, the measure wo...   \n",
       "\n",
       "                                          lead_paragraph       section  hits  \\\n",
       "0      SAN FRANCISCO â€” If you have sent email on Goog...    Technology  1259   \n",
       "1      THIS week, Bill Cosby was charged with three c...       Opinion  1514   \n",
       "2      WASHINGTON â€” The question from the congressman...          U.S.  2394   \n",
       "3      Larry Summers, Brad DeLong, and yours truly ar...       Opinion  3998   \n",
       "4      Nearly three years ago, when I first thought a...       Opinion  6215   \n",
       "...                                                  ...           ...   ...   \n",
       "18734  Customers flocking to Starbucks and ordering P...  Business Day  1849   \n",
       "18735  McDonaldâ€™s will begin reopening its restaurant...  Business Day  1849   \n",
       "18736  HICKORY, N.C. â€” On a chilly spring evening in ...       Opinion  1849   \n",
       "18737  McDonaldâ€™s announced a shake-up of its board o...  Business Day  1849   \n",
       "18738  The California State Senate passed a bill on M...  Business Day  1849   \n",
       "\n",
       "       word_count  \n",
       "0            1180  \n",
       "1             914  \n",
       "2            1189  \n",
       "3             576  \n",
       "4             440  \n",
       "...           ...  \n",
       "18734         343  \n",
       "18735         314  \n",
       "18736        2171  \n",
       "18737         492  \n",
       "18738         969  \n",
       "\n",
       "[18739 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(df.groupby('date').count()['headline'])\n",
    "temp = temp.rename(columns={'headline': 'article_count'})\n",
    "temp = temp.reindex(pd.date_range(start=\"2016-01-01\", end=\"2022-09-01\"))\n",
    "temp = temp.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_count    7.692529\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 articles: 27\n",
      "<5 articles: 647\n"
     ]
    }
   ],
   "source": [
    "zero = len(temp[temp['article_count']==0])\n",
    "print(f'0 articles: {zero}')\n",
    "\n",
    "less_five = len(temp[temp['article_count']<5])\n",
    "print(f'<5 articles: {less_five}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d4736924dd4ee01619834d3df5aac36876c141d93beb7feebfa3d7eb88b873d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
