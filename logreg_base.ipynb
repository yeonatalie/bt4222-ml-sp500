{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.0.0)/charset_normalizer (2.0.6) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import itertools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from feature_engineering import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3perc_lag3 = pd.read_excel(\"data/model_inputs/x_train_3perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date').dropna()\n",
    "X_test_3perc_lag3 = pd.read_excel(\"data/model_inputs/x_test_3perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_train_3perc_lag3 = pd.read_excel(\"data/model_inputs/y_train_3perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date').reindex(X_train_3perc_lag3.index)\n",
    "y_test_3perc_lag3 = pd.read_excel(\"data/model_inputs/y_test_3perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "\n",
    "X_train_3perc_lag7 = pd.read_excel(\"data/model_inputs/x_train_3perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date').dropna()\n",
    "X_test_3perc_lag7 = pd.read_excel(\"data/model_inputs/x_test_3perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_train_3perc_lag7 = pd.read_excel(\"data/model_inputs/y_train_3perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date').reindex(X_train_3perc_lag7.index)\n",
    "y_test_3perc_lag7 = pd.read_excel(\"data/model_inputs/y_test_3perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "\n",
    "X_train_5perc_lag3 = pd.read_excel(\"data/model_inputs/x_train_5perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date').dropna()\n",
    "X_test_5perc_lag3 = pd.read_excel(\"data/model_inputs/x_test_5perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_train_5perc_lag3 = pd.read_excel(\"data/model_inputs/y_train_5perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date').reindex(X_train_5perc_lag3.index)\n",
    "y_test_5perc_lag3 = pd.read_excel(\"data/model_inputs/y_test_5perc_lag3.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "\n",
    "X_train_5perc_lag7 = pd.read_excel(\"data/model_inputs/x_train_5perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date').dropna()\n",
    "X_test_5perc_lag7 = pd.read_excel(\"data/model_inputs/x_test_5perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')\n",
    "y_train_5perc_lag7 = pd.read_excel(\"data/model_inputs/y_train_5perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date').reindex(X_train_5perc_lag7.index)\n",
    "y_test_5perc_lag7 = pd.read_excel(\"data/model_inputs/y_test_5perc_lag7.xlsx\").rename(columns={'Unnamed: 0':'date'}).set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate config and feature combinations to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "included_columns = ['adj_close', 'reddit_pos_both', 'reddit_neg_both', 'reddit_neu_both', 'nyt_pos', 'nyt_neg', 'nyt_neu']\n",
    "gdp = ['quarterly_gdp_actual','quarterly_gdp_growth']\n",
    "cpi = ['monthly_cpi_actual','monthly_cpi_growth']\n",
    "ir = ['monthly_st_ir_actual','monthly_st_ir_growth']\n",
    "unemployment = ['monthly_unemployment_actual', 'monthly_unemployment_growth']\n",
    "macro_combinations = list(itertools.product(gdp,cpi,ir,unemployment))\n",
    "macro_combinations = [list(x) for x in macro_combinations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_combinations = []\n",
    "for x in macro_combinations:\n",
    "    feature_combinations.append(list(np.append(x, included_columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote(X_train, y_train):\n",
    "    sm = SMOTE(sampling_strategy='not majority')\n",
    "    X_train_oversampled, y_train_oversampled = sm.fit_resample(X_train, y_train)\n",
    "    return X_train_oversampled, y_train_oversampled\n",
    "\n",
    "def random_oversampler(X_train, y_train):\n",
    "    oversample = RandomOverSampler(sampling_strategy='not majority')\n",
    "    X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
    "    return X_over, y_over\n",
    "\n",
    "def adasyn(X_train, y_train):\n",
    "    ada = ADASYN(sampling_strategy = 'not majority')\n",
    "    X_resampled, y_resampled = ADASYN().fit_resample(X_train, y_train)\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test configs and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_col, lag_col, oversampling_method, used_features, accuracy, precision, recall, f1, pred_count = [], [], [], [], [], [], [], [], []\n",
    "for perc in ['3perc', '5perc']:\n",
    "    for lag in [3, 7]:\n",
    "        for oversampling in ['smote', 'random_oversampler', 'adasyn']:\n",
    "            for features in feature_combinations:\n",
    "                X_train = eval(f'X_train_{perc}_lag{lag}')\n",
    "                X_test = eval(f'X_test_{perc}_lag{lag}')\n",
    "                y_train = eval(f'y_train_{perc}_lag{lag}')\n",
    "                y_test = eval(f'y_test_{perc}_lag{lag}')\n",
    "\n",
    "                # oversampling\n",
    "                if oversampling == 'smote':\n",
    "                    X_train_oversampled, y_train_oversampled = smote(X_train, y_train)\n",
    "                elif oversampling == 'random_oversampler':\n",
    "                    X_train_oversampled, y_train_oversampled = random_oversampler(X_train, y_train)\n",
    "                else:\n",
    "                    X_train_oversampled, y_train_oversampled = adasyn(X_train, y_train)\n",
    "\n",
    "                # fit and predict\n",
    "                lr = LogisticRegression()\n",
    "                pred = lr.fit(X_train_oversampled, y_train_oversampled).predict(X_test)\n",
    "                \n",
    "                # update columns\n",
    "                perc_col.append(perc)\n",
    "                lag_col.append(lag)\n",
    "                oversampling_method.append(oversampling)\n",
    "                used_features.append(features)\n",
    "                accuracy.append(accuracy_score(y_test, pred))\n",
    "                precision.append(precision_score(y_test, pred, average='weighted'))\n",
    "                recall.append(recall_score(y_test, pred, average='weighted'))\n",
    "                f1.append(f1_score(y_test, pred, average='weighted'))\n",
    "                pred_count.append(dict(pd.Series(pred).value_counts().sort_index()))\n",
    "\n",
    "base_results = pd.DataFrame({\n",
    "    'model': \"Logistic Regression\",\n",
    "    'perc_threshold': perc_col,\n",
    "    'lag': lag_col,\n",
    "    'oversampling': oversampling_method,\n",
    "    'features': used_features,\n",
    "    'accuracy': accuracy,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1': f1,\n",
    "    'pred_count': pred_count\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>perc_threshold</th>\n",
       "      <th>lag</th>\n",
       "      <th>oversampling</th>\n",
       "      <th>features</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>pred_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>3</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>[quarterly_gdp_growth, monthly_cpi_growth, mon...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.644260</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.654514</td>\n",
       "      <td>{-1: 1, 0: 141, 1: 26}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>3</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>[quarterly_gdp_actual, monthly_cpi_actual, mon...</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.651786</td>\n",
       "      <td>{-1: 1, 0: 137, 1: 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>3</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>[quarterly_gdp_growth, monthly_cpi_growth, mon...</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.646161</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.649503</td>\n",
       "      <td>{-1: 1, 0: 138, 1: 29}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>3</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>[quarterly_gdp_growth, monthly_cpi_growth, mon...</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.649426</td>\n",
       "      <td>{0: 138, 1: 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5perc</td>\n",
       "      <td>3</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>[quarterly_gdp_actual, monthly_cpi_actual, mon...</td>\n",
       "      <td>0.636905</td>\n",
       "      <td>0.651629</td>\n",
       "      <td>0.636905</td>\n",
       "      <td>0.642945</td>\n",
       "      <td>{0: 133, 1: 35}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>3perc</td>\n",
       "      <td>7</td>\n",
       "      <td>random_oversampler</td>\n",
       "      <td>[quarterly_gdp_actual, monthly_cpi_growth, mon...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.677112</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.269107</td>\n",
       "      <td>{-1: 12, 0: 11, 1: 145}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>3perc</td>\n",
       "      <td>3</td>\n",
       "      <td>smote</td>\n",
       "      <td>[quarterly_gdp_growth, monthly_cpi_growth, mon...</td>\n",
       "      <td>0.327381</td>\n",
       "      <td>0.599741</td>\n",
       "      <td>0.327381</td>\n",
       "      <td>0.263626</td>\n",
       "      <td>{-1: 20, 0: 10, 1: 138}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>3perc</td>\n",
       "      <td>3</td>\n",
       "      <td>smote</td>\n",
       "      <td>[quarterly_gdp_growth, monthly_cpi_growth, mon...</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.524772</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.263370</td>\n",
       "      <td>{-1: 23, 0: 12, 1: 133}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>3perc</td>\n",
       "      <td>3</td>\n",
       "      <td>smote</td>\n",
       "      <td>[quarterly_gdp_actual, monthly_cpi_actual, mon...</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.512057</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.261338</td>\n",
       "      <td>{-1: 26, 0: 12, 1: 130}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>3perc</td>\n",
       "      <td>3</td>\n",
       "      <td>smote</td>\n",
       "      <td>[quarterly_gdp_growth, monthly_cpi_actual, mon...</td>\n",
       "      <td>0.315476</td>\n",
       "      <td>0.518246</td>\n",
       "      <td>0.315476</td>\n",
       "      <td>0.256262</td>\n",
       "      <td>{-1: 22, 0: 12, 1: 134}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model perc_threshold  lag        oversampling  \\\n",
       "127  Logistic Regression          5perc    3  random_oversampler   \n",
       "114  Logistic Regression          5perc    3  random_oversampler   \n",
       "125  Logistic Regression          5perc    3  random_oversampler   \n",
       "126  Logistic Regression          5perc    3  random_oversampler   \n",
       "113  Logistic Regression          5perc    3  random_oversampler   \n",
       "..                   ...            ...  ...                 ...   \n",
       "70   Logistic Regression          3perc    7  random_oversampler   \n",
       "15   Logistic Regression          3perc    3               smote   \n",
       "12   Logistic Regression          3perc    3               smote   \n",
       "0    Logistic Regression          3perc    3               smote   \n",
       "9    Logistic Regression          3perc    3               smote   \n",
       "\n",
       "                                              features  accuracy  precision  \\\n",
       "127  [quarterly_gdp_growth, monthly_cpi_growth, mon...  0.666667   0.644260   \n",
       "114  [quarterly_gdp_actual, monthly_cpi_actual, mon...  0.654762   0.650794   \n",
       "125  [quarterly_gdp_growth, monthly_cpi_growth, mon...  0.654762   0.646161   \n",
       "126  [quarterly_gdp_growth, monthly_cpi_growth, mon...  0.654762   0.646092   \n",
       "113  [quarterly_gdp_actual, monthly_cpi_actual, mon...  0.636905   0.651629   \n",
       "..                                                 ...       ...        ...   \n",
       "70   [quarterly_gdp_actual, monthly_cpi_growth, mon...  0.333333   0.677112   \n",
       "15   [quarterly_gdp_growth, monthly_cpi_growth, mon...  0.327381   0.599741   \n",
       "12   [quarterly_gdp_growth, monthly_cpi_growth, mon...  0.321429   0.524772   \n",
       "0    [quarterly_gdp_actual, monthly_cpi_actual, mon...  0.321429   0.512057   \n",
       "9    [quarterly_gdp_growth, monthly_cpi_actual, mon...  0.315476   0.518246   \n",
       "\n",
       "       recall        f1               pred_count  \n",
       "127  0.666667  0.654514   {-1: 1, 0: 141, 1: 26}  \n",
       "114  0.654762  0.651786   {-1: 1, 0: 137, 1: 30}  \n",
       "125  0.654762  0.649503   {-1: 1, 0: 138, 1: 29}  \n",
       "126  0.654762  0.649426          {0: 138, 1: 30}  \n",
       "113  0.636905  0.642945          {0: 133, 1: 35}  \n",
       "..        ...       ...                      ...  \n",
       "70   0.333333  0.269107  {-1: 12, 0: 11, 1: 145}  \n",
       "15   0.327381  0.263626  {-1: 20, 0: 10, 1: 138}  \n",
       "12   0.321429  0.263370  {-1: 23, 0: 12, 1: 133}  \n",
       "0    0.321429  0.261338  {-1: 26, 0: 12, 1: 130}  \n",
       "9    0.315476  0.256262  {-1: 22, 0: 12, 1: 134}  \n",
       "\n",
       "[192 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_results.sort_values(by=\"f1\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model                                           Logistic Regression\n",
       "perc_threshold                                                5perc\n",
       "lag                                                               3\n",
       "oversampling                                     random_oversampler\n",
       "features          [quarterly_gdp_growth, monthly_cpi_growth, mon...\n",
       "accuracy                                                   0.666667\n",
       "precision                                                   0.64426\n",
       "recall                                                     0.666667\n",
       "f1                                                         0.654514\n",
       "pred_count                                   {-1: 1, 0: 141, 1: 26}\n",
       "Name: 127, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_results.sort_values(by=\"f1\", ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quarterly_gdp_growth',\n",
       " 'monthly_cpi_growth',\n",
       " 'monthly_st_ir_growth',\n",
       " 'monthly_unemployment_growth',\n",
       " 'adj_close',\n",
       " 'reddit_pos_both',\n",
       " 'reddit_neg_both',\n",
       " 'reddit_neu_both',\n",
       " 'nyt_pos',\n",
       " 'nyt_neg',\n",
       " 'nyt_neu']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_results.sort_values(by=\"f1\", ascending=False).iloc[0]['features']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate X_train, y_train, X_test, y_test based on best config and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "best_perc, best_lag = 0.05, 3\n",
    "\n",
    "# target column\n",
    "target = create_target(best_perc)\n",
    "target = target.replace({'BUY':1, 'HOLD':0, 'SELL':-1})\n",
    "target = target.drop(['Adj Close'], axis=1)\n",
    "\n",
    "# feature: index price\n",
    "prices = yf.download(\"^GSPC\", start=\"2015-12-01\", end=\"2022-09-02\")[['Adj Close']]\n",
    "prices = compute_lagged_values(prices, best_lag, \"mean\")\n",
    "prices = prices.reset_index()\n",
    "prices['Date'] = prices['Date'].apply(lambda x: x.date())\n",
    "prices = prices.set_index('Date')\n",
    "prices.index = pd.DatetimeIndex(prices.index)\n",
    "prices = prices[prices.index.isin(target.index)]\n",
    "\n",
    "# feature: reddit scores\n",
    "reddit_scores = pd.read_excel(\"data/sentiments/reddit_2016_2022_sentiment_scores.xlsx\")\n",
    "reddit_scores = reddit_scores.set_index('date')\n",
    "reddit_scores = compute_lagged_values(reddit_scores, best_lag, \"mean\")\n",
    "reddit_scores = reddit_scores[reddit_scores.index.isin(target.index)]\n",
    "weight_type = \"both\" # or \"comments\", \"upvotes\"\n",
    "reddit_scores = reddit_scores[[f'pos_score_weighted_{weight_type}',f'neg_score_weighted_{weight_type}',f'neu_score_weighted_{weight_type}',f'compound_score_weighted_{weight_type}']]\n",
    "\n",
    "# feature: news scores\n",
    "nyt_scores = pd.read_excel(\"data/sentiments/nyt_2016_2022_sentiment_scores.xlsx\")\n",
    "nyt_scores = nyt_scores.set_index('date')\n",
    "nyt_scores = compute_lagged_values(nyt_scores, best_lag, \"mean\")\n",
    "nyt_scores = nyt_scores[nyt_scores.index.isin(target.index)]\n",
    "\n",
    "# feature: macro data\n",
    "macro_data = pd.read_excel(\"data/raw/Macro_Data_2016_to_2022.xlsx\")\n",
    "macro_data = macro_feature_engineer(macro_data, data_type=\"growth\") # best results uses all growth for macro features\n",
    "macro_data = macro_data.reindex(target.index)\n",
    "macro_data = macro_data[macro_data.index.isin(target.index)]\n",
    "\n",
    "# Combine features and target\n",
    "data = pd.concat([prices, reddit_scores, nyt_scores, macro_data, target], axis=1)\n",
    "\n",
    "# Train-test split\n",
    "X, y = data.drop(columns={'decision'}), data[['decision']]\n",
    "X = X.drop(['Unnamed: 0', 'pos_score', 'neg_score','neu_score','compound_score_weighted_both'], axis = 1)\n",
    "X.rename({'pos_score_weighted_both': 'reddit_pos_both', 'neg_score_weighted_both': 'reddit_neg_both', 'neu_score_weighted_both': 'reddit_neu_both', 'pos_weighted':'nyt_pos','neg_weighted':'nyt_neg','neu_weighted':'nyt_neu','Adj Close':'adj_close','Quarterly GDP (Growth)':'quarterly_gdp_growth','Monthly CPI (Growth)':'monthly_cpi_growth','Monthly Short Term Interest Rates (Growth)':'monthly_st_ir_growth','Monthly Unemployment Rate (Growth)':'monthly_unemployment_growth'}, axis = 1, inplace = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=len(data['2022':]), shuffle=False)\n",
    "\n",
    "scaler = StandardScaler() \n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "X_train_scaled = X_train_scaled.set_index(X_train.index)\n",
    "\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "X_test_scaled = X_test_scaled.set_index(X_test.index)\n",
    "\n",
    "X_train_scaled.to_excel(f'data/model_inputs/X_train.xlsx')\n",
    "X_test_scaled.to_excel(f'data/model_inputs/X_test.xlsx')\n",
    "y_train.to_excel(f'data/model_inputs/y_train.xlsx')\n",
    "y_test.to_excel(f'data/model_inputs/y_test.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
